{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import socket\n",
    "import requests\n",
    "\n",
    "from transformers import AutoConfig\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from sentence_transformers import util\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED\t\t\t: config\n"
     ]
    }
   ],
   "source": [
    "with open('config.json', 'r') as file:\n",
    "    config = json.load(file)\n",
    "print(\"LOADED\\t\\t\\t: config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test question_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_checker(question, refq, treshold=0.5, model=None):\n",
    "    if model is not None:\n",
    "        emb_refq = model.encode(refq)\n",
    "        emb_actq = model.encode([question])\n",
    "\n",
    "        cosine_similarities = util.cos_sim(emb_refq, emb_actq)\n",
    "        # print([[sim > treshold, sim] for sim in cosine_similarities[0]])\n",
    "        return any(sim > treshold for sim in cosine_similarities)\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_st = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "question = \"What is the bread?\"\n",
    "positive_question_1 = \"What is the bread?\"\n",
    "positive_question_2 = \"What is the soft bread?\"\n",
    "neagtive_question_1 = \"What is the formula one car?\"\n",
    "negative_question_2 = \"How old are you?\"\n",
    "    \n",
    "assert question_checker(question, [positive_question_1], 0.99, model=model_st) == True\n",
    "assert question_checker(question, [positive_question_2], 0.99, model=model_st) == False\n",
    "assert question_checker(question, [positive_question_2], 0.5, model=model_st) == True\n",
    "assert question_checker(question, [neagtive_question_1], 0.5, model=model_st) == False\n",
    "assert question_checker(question, [negative_question_2], 0.1, model=model_st) == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cleaning_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_stream(batch):\n",
    "    if len(batch['text_output']) == 0:\n",
    "        return False\n",
    "    elif batch['text_output'] == \"\\n\\n\":\n",
    "        return False\n",
    "    elif \"<|start_header_id|>\" in batch['text_output']:\n",
    "        return False\n",
    "    elif \"assistant\" in batch['text_output']:\n",
    "        return False\n",
    "    elif \"<|end_header_id|>\" in batch['text_output']:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {'text_output': \"\"}\n",
    "assert cleaning_stream(batch) == False\n",
    "\n",
    "# 2. Csak új sorokból áll\n",
    "batch = {'text_output': \"\\n\\n\"}\n",
    "assert cleaning_stream(batch) == False\n",
    "\n",
    "# 3. \"<|start_header_id|>\" szöveget tartalmaz\n",
    "batch = {'text_output': \"This is some text with <|start_header_id|> in it\"}\n",
    "assert cleaning_stream(batch) == False\n",
    "\n",
    "# 4. \"assistant\" szöveget tartalmaz\n",
    "batch = {'text_output': \"This is some text with assistant in it\"}\n",
    "assert cleaning_stream(batch) == False\n",
    "\n",
    "# 5. \"<|end_header_id|>\" szöveget tartalmaz\n",
    "batch = {'text_output': \"This is some text with <|end_header_id|> in it\"}\n",
    "assert cleaning_stream(batch) == False\n",
    "\n",
    "# 6. Minden feltételnek megfelelő szöveg (nincs tiltott karakter vagy string)\n",
    "batch = {'text_output': \"This is a valid text output\"}\n",
    "assert cleaning_stream(batch) == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test reduce_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKENIZER\t\t: meta-llama/Llama-3.1-8b-instruct\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config[\"tokenizer\"])\n",
    "print(\"TOKENIZER\\t\\t:\", config[\"tokenizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX TOKEN INPUT SIZE\t: 131072\n"
     ]
    }
   ],
   "source": [
    "autoconfig = AutoConfig.from_pretrained(config[\"tokenizer\"])\n",
    "limit_pe = autoconfig.max_position_embeddings - config[\"guard\"][\"reduce_max_position_embeddings\"]\n",
    "print(\"MAX TOKEN INPUT SIZE\\t:\", autoconfig.max_position_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_message(chat, max_len, num_limit, tokenizer):\n",
    "    message = tokenizer.apply_chat_template(chat, tokenize=False)\n",
    "    len_chat = len(tokenizer.encode(message))      \n",
    "    while len_chat > max_len and len(chat) > num_limit:\n",
    "        chat = chat[0:1] + chat[2:]\n",
    "\n",
    "        message = tokenizer.apply_chat_template(chat, tokenize=False)\n",
    "        len_chat = len(tokenizer.encode(message))\n",
    "        # print(len_chat, chat)\n",
    "\n",
    "    if len_chat < max_len:\n",
    "        return message\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "Some content.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Some content.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Some content.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Some content.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Some content.<|eot_id|>\n",
      "46\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "Some content.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Some content.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Some content.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "chat = [\n",
    "    {\"role\": \"system\", \"content\": \"Some content.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Some content.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Some content.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Some content.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Some content.\"}]\n",
    "\n",
    "message = tokenizer.apply_chat_template(chat, tokenize=False)\n",
    "print(len(tokenizer.encode(message)))\n",
    "print(message)\n",
    "\n",
    "# print()\n",
    "\n",
    "assert len(tokenizer.encode(reduce_message(chat, 60, 3, tokenizer))) <= 60\n",
    "assert len(tokenizer.encode(reduce_message(chat, 50, 3, tokenizer))) <= 50\n",
    "assert len(tokenizer.encode(reduce_message(chat, 40, 3, tokenizer))) == 1\n",
    "\n",
    "message = reduce_message(chat, 50, 3, tokenizer)\n",
    "print(len(tokenizer.encode(message)))\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL\t\t\t: http://172.22.214.120:28800/v2/models/llama-3.1-8b-instruct/generate_stream\n"
     ]
    }
   ],
   "source": [
    "url = f\"{config['triton']['host']}:{config['triton']['port']}/v2/{config['triton']['model']}/{config['triton']['generation']}\"\n",
    "print(\"URL\\t\\t\\t:\", url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mennyi volt az átlagos páratartalom 2024.09.16-án 10 órakkor.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Mennyi volt az átlagos páratartalom 2024.09.16-án 10 órakkor.\"\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "if question_checker(question=question, \n",
    "                    refq=config[\"filters\"][\"reference questions\"], \n",
    "                    treshold=config[\"filters\"][\"treshold\"], \n",
    "                    model=model_st):\n",
    "    print(\"Ok\")\n",
    "else:\n",
    "    print(config[\"guard\"][\"no information\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED\t\t\t: data\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{config['sources']}/total.json\", 'r') as file:\n",
    "    data = json.load(file)\n",
    "print(\"LOADED\\t\\t\\t: data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10704"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reinforce = \" Csak a kérdésre válaszolj! Ne magyarázd a válaszod és ne sorolj fel részadatokat de teljes mondatban válaszolj!\"\n",
    "chat = config[\"chat history\"].copy()\n",
    "chat[-1][\"content\"] = f\"Páratartalom adatai (JSON):{str(data)}\\n\\n\"\n",
    "chat.append({\"role\": \"user\", \"content\": question + reinforce})\n",
    "\n",
    "message = tokenizer.apply_chat_template(chat, tokenize=False)\n",
    "\n",
    "len(tokenizer.encode(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nPáratartalom adatai (JSON):[{'_óra_': 1, '_átlag_': '58.525%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 1 óra/h'}, {'_óra_': 2, '_átlag_': '45.433%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 2 óra/h'}, {'_óra_': 3, '_átlag_': '43.525%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 3 óra/h'}, {'_óra_': 4, '_átlag_': '47.317%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 4 óra/h'}, {'_óra_': 5, '_átlag_': '47.22%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 5 óra/h'}, {'_óra_': 6, '_átlag_': '51.567%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 6 óra/h'}, {'_óra_': 7, '_átlag_': '42.883%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 7 óra/h'}, {'_óra_': 8, '_átlag_': '43.915%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 8 óra/h'}, {'_óra_': 9, '_átlag_': '47.77%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 9 óra/h'}, {'_óra_': 10, '_átlag_': '44.186%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 10 óra/h'}, {'_óra_': 11, '_átlag_': '50.983%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 11 óra/h'}, {'_óra_': 12, '_átlag_': '53.217%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 12 óra/h'}, {'_óra_': 13, '_átlag_': '44.852%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 13 óra/h'}, {'_óra_': 14, '_átlag_': '55.683%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 14 óra/h'}, {'_óra_': 15, '_átlag_': '49.213%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 15 óra/h'}, {'_óra_': 16, '_átlag_': '58.1%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 16 óra/h'}, {'_óra_': 17, '_átlag_': '51.817%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 17 óra/h'}, {'_óra_': 18, '_átlag_': '48.683%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 18 óra/h'}, {'_óra_': 19, '_átlag_': '50.2%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 19 óra/h'}, {'_óra_': 20, '_átlag_': '47.95%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 20 óra/h'}, {'_óra_': 21, '_átlag_': '39.85%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 21 óra/h'}, {'_óra_': 22, '_átlag_': '49.898%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 22 óra/h'}, {'_óra_': 23, '_átlag_': '46.3%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 23 óra/h'}, {'_óra_': 24, '_átlag_': '47.267%', '_év_': '2024', '_hónap_': '09', '_nap_': '10', '_dátum_': '2024.09.10 24 óra/h'}, {'_óra_': 1, '_átlag_': '47.5%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 1 óra/h'}, {'_óra_': 2, '_átlag_': '43.678%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 2 óra/h'}, {'_óra_': 3, '_átlag_': '53.644%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 3 óra/h'}, {'_óra_': 4, '_átlag_': '44.066%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 4 óra/h'}, {'_óra_': 5, '_átlag_': '54.373%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 5 óra/h'}, {'_óra_': 6, '_átlag_': '48.115%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 6 óra/h'}, {'_óra_': 7, '_átlag_': '49.967%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 7 óra/h'}, {'_óra_': 8, '_átlag_': '48.783%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 8 óra/h'}, {'_óra_': 9, '_átlag_': '47.683%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 9 óra/h'}, {'_óra_': 10, '_átlag_': '44.746%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 10 óra/h'}, {'_óra_': 11, '_átlag_': '57.267%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 11 óra/h'}, {'_óra_': 12, '_átlag_': '49.833%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 12 óra/h'}, {'_óra_': 13, '_átlag_': '48.967%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 13 óra/h'}, {'_óra_': 14, '_átlag_': '43.45%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 14 óra/h'}, {'_óra_': 15, '_átlag_': '46.559%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 15 óra/h'}, {'_óra_': 16, '_átlag_': '54.733%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 16 óra/h'}, {'_óra_': 17, '_átlag_': '50.25%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 17 óra/h'}, {'_óra_': 18, '_átlag_': '49.322%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 18 óra/h'}, {'_óra_': 19, '_átlag_': '43.283%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 19 óra/h'}, {'_óra_': 20, '_átlag_': '49.167%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 20 óra/h'}, {'_óra_': 21, '_átlag_': '49.443%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 21 óra/h'}, {'_óra_': 22, '_átlag_': '49.254%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 22 óra/h'}, {'_óra_': 23, '_átlag_': '41.361%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 23 óra/h'}, {'_óra_': 24, '_átlag_': '48.803%', '_év_': '2024', '_hónap_': '09', '_nap_': '11', '_dátum_': '2024.09.11 24 óra/h'}, {'_óra_': 1, '_átlag_': '46.119%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 1 óra/h'}, {'_óra_': 2, '_átlag_': '49.213%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 2 óra/h'}, {'_óra_': 3, '_átlag_': '44.233%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 3 óra/h'}, {'_óra_': 4, '_átlag_': '48.322%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 4 óra/h'}, {'_óra_': 5, '_átlag_': '50.95%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 5 óra/h'}, {'_óra_': 6, '_átlag_': '54.847%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 6 óra/h'}, {'_óra_': 7, '_átlag_': '56.617%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 7 óra/h'}, {'_óra_': 8, '_átlag_': '48.117%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 8 óra/h'}, {'_óra_': 9, '_átlag_': '49.783%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 9 óra/h'}, {'_óra_': 10, '_átlag_': '47.667%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 10 óra/h'}, {'_óra_': 11, '_átlag_': '45.767%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 11 óra/h'}, {'_óra_': 12, '_átlag_': '52.424%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 12 óra/h'}, {'_óra_': 13, '_átlag_': '49.2%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 13 óra/h'}, {'_óra_': 14, '_átlag_': '49.213%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 14 óra/h'}, {'_óra_': 15, '_átlag_': '50.267%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 15 óra/h'}, {'_óra_': 16, '_átlag_': '57.847%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 16 óra/h'}, {'_óra_': 17, '_átlag_': '55.783%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 17 óra/h'}, {'_óra_': 18, '_átlag_': '49.583%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 18 óra/h'}, {'_óra_': 19, '_átlag_': '50.233%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 19 óra/h'}, {'_óra_': 20, '_átlag_': '50.917%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 20 óra/h'}, {'_óra_': 21, '_átlag_': '53.067%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 21 óra/h'}, {'_óra_': 22, '_átlag_': '50.639%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 22 óra/h'}, {'_óra_': 23, '_átlag_': '46.644%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 23 óra/h'}, {'_óra_': 24, '_átlag_': '45.317%', '_év_': '2024', '_hónap_': '09', '_nap_': '12', '_dátum_': '2024.09.12 24 óra/h'}, {'_óra_': 1, '_átlag_': '47.817%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 1 óra/h'}, {'_óra_': 2, '_átlag_': '56.475%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 2 óra/h'}, {'_óra_': 3, '_átlag_': '52.733%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 3 óra/h'}, {'_óra_': 4, '_átlag_': '50.267%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 4 óra/h'}, {'_óra_': 5, '_átlag_': '44.117%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 5 óra/h'}, {'_óra_': 6, '_átlag_': '49.1%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 6 óra/h'}, {'_óra_': 7, '_átlag_': '50.2%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 7 óra/h'}, {'_óra_': 8, '_átlag_': '45.917%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 8 óra/h'}, {'_óra_': 9, '_átlag_': '50.75%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 9 óra/h'}, {'_óra_': 10, '_átlag_': '53.254%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 10 óra/h'}, {'_óra_': 11, '_átlag_': '49.583%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 11 óra/h'}, {'_óra_': 12, '_átlag_': '47.607%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 12 óra/h'}, {'_óra_': 13, '_átlag_': '45.627%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 13 óra/h'}, {'_óra_': 14, '_átlag_': '44.672%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 14 óra/h'}, {'_óra_': 15, '_átlag_': '51.847%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 15 óra/h'}, {'_óra_': 16, '_átlag_': '47.867%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 16 óra/h'}, {'_óra_': 17, '_átlag_': '51.683%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 17 óra/h'}, {'_óra_': 18, '_átlag_': '46.115%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 18 óra/h'}, {'_óra_': 19, '_átlag_': '47.661%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 19 óra/h'}, {'_óra_': 20, '_átlag_': '48.049%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 20 óra/h'}, {'_óra_': 21, '_átlag_': '49.984%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 21 óra/h'}, {'_óra_': 22, '_átlag_': '46.467%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 22 óra/h'}, {'_óra_': 23, '_átlag_': '48.633%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 23 óra/h'}, {'_óra_': 24, '_átlag_': '53.932%', '_év_': '2024', '_hónap_': '09', '_nap_': '13', '_dátum_': '2024.09.13 24 óra/h'}, {'_óra_': 1, '_átlag_': '52.233%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 1 óra/h'}, {'_óra_': 2, '_átlag_': '55.763%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 2 óra/h'}, {'_óra_': 3, '_átlag_': '50.183%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 3 óra/h'}, {'_óra_': 4, '_átlag_': '53.483%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 4 óra/h'}, {'_óra_': 5, '_átlag_': '51.967%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 5 óra/h'}, {'_óra_': 6, '_átlag_': '51.05%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 6 óra/h'}, {'_óra_': 7, '_átlag_': '44.883%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 7 óra/h'}, {'_óra_': 8, '_átlag_': '44.017%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 8 óra/h'}, {'_óra_': 9, '_átlag_': '44.567%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 9 óra/h'}, {'_óra_': 10, '_átlag_': '45.35%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 10 óra/h'}, {'_óra_': 11, '_átlag_': '47.783%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 11 óra/h'}, {'_óra_': 12, '_átlag_': '52.262%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 12 óra/h'}, {'_óra_': 13, '_átlag_': '51.328%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 13 óra/h'}, {'_óra_': 14, '_átlag_': '48.017%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 14 óra/h'}, {'_óra_': 15, '_átlag_': '47.7%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 15 óra/h'}, {'_óra_': 16, '_átlag_': '47.424%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 16 óra/h'}, {'_óra_': 17, '_átlag_': '55.35%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 17 óra/h'}, {'_óra_': 18, '_átlag_': '51.25%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 18 óra/h'}, {'_óra_': 19, '_átlag_': '48.617%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 19 óra/h'}, {'_óra_': 20, '_átlag_': '51.098%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 20 óra/h'}, {'_óra_': 21, '_átlag_': '38.492%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 21 óra/h'}, {'_óra_': 22, '_átlag_': '52.7%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 22 óra/h'}, {'_óra_': 23, '_átlag_': '49.933%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 23 óra/h'}, {'_óra_': 24, '_átlag_': '46.65%', '_év_': '2024', '_hónap_': '09', '_nap_': '14', '_dátum_': '2024.09.14 24 óra/h'}, {'_óra_': 1, '_átlag_': '56.458%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 1 óra/h'}, {'_óra_': 2, '_átlag_': '41.541%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 2 óra/h'}, {'_óra_': 3, '_átlag_': '48.45%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 3 óra/h'}, {'_óra_': 4, '_átlag_': '49.183%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 4 óra/h'}, {'_óra_': 5, '_átlag_': '50.885%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 5 óra/h'}, {'_óra_': 6, '_átlag_': '40.25%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 6 óra/h'}, {'_óra_': 7, '_átlag_': '47.35%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 7 óra/h'}, {'_óra_': 8, '_átlag_': '52.667%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 8 óra/h'}, {'_óra_': 9, '_átlag_': '52.017%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 9 óra/h'}, {'_óra_': 10, '_átlag_': '51.8%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 10 óra/h'}, {'_óra_': 11, '_átlag_': '53.393%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 11 óra/h'}, {'_óra_': 12, '_átlag_': '46.373%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 12 óra/h'}, {'_óra_': 13, '_átlag_': '43.117%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 13 óra/h'}, {'_óra_': 14, '_átlag_': '53.283%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 14 óra/h'}, {'_óra_': 15, '_átlag_': '60.136%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 15 óra/h'}, {'_óra_': 16, '_átlag_': '47.983%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 16 óra/h'}, {'_óra_': 17, '_átlag_': '48.083%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 17 óra/h'}, {'_óra_': 18, '_átlag_': '51.797%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 18 óra/h'}, {'_óra_': 19, '_átlag_': '47.683%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 19 óra/h'}, {'_óra_': 20, '_átlag_': '44.65%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 20 óra/h'}, {'_óra_': 21, '_átlag_': '54.39%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 21 óra/h'}, {'_óra_': 22, '_átlag_': '50.213%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 22 óra/h'}, {'_óra_': 23, '_átlag_': '56.117%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 23 óra/h'}, {'_óra_': 24, '_átlag_': '47.783%', '_év_': '2024', '_hónap_': '09', '_nap_': '15', '_dátum_': '2024.09.15 24 óra/h'}, {'_óra_': 1, '_átlag_': '52.169%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 1 óra/h'}, {'_óra_': 2, '_átlag_': '44.557%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 2 óra/h'}, {'_óra_': 3, '_átlag_': '50.417%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 3 óra/h'}, {'_óra_': 4, '_átlag_': '51.467%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 4 óra/h'}, {'_óra_': 5, '_átlag_': '46.883%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 5 óra/h'}, {'_óra_': 6, '_átlag_': '51.661%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 6 óra/h'}, {'_óra_': 7, '_átlag_': '45.869%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 7 óra/h'}, {'_óra_': 8, '_átlag_': '59.033%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 8 óra/h'}, {'_óra_': 9, '_átlag_': '47.949%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 9 óra/h'}, {'_óra_': 10, '_átlag_': '53.483%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 10 óra/h'}, {'_óra_': 11, '_átlag_': '49.95%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 11 óra/h'}, {'_óra_': 12, '_átlag_': '56.441%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 12 óra/h'}, {'_óra_': 13, '_átlag_': '46.883%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 13 óra/h'}, {'_óra_': 14, '_átlag_': '40.517%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 14 óra/h'}, {'_óra_': 15, '_átlag_': '48.6%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 15 óra/h'}, {'_óra_': 16, '_átlag_': '46.867%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 16 óra/h'}, {'_óra_': 17, '_átlag_': '54.9%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 17 óra/h'}, {'_óra_': 18, '_átlag_': '50.4%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 18 óra/h'}, {'_óra_': 19, '_átlag_': '56.55%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 19 óra/h'}, {'_óra_': 20, '_átlag_': '44.867%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 20 óra/h'}, {'_óra_': 21, '_átlag_': '58.279%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 21 óra/h'}, {'_óra_': 22, '_átlag_': '45.183%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 22 óra/h'}, {'_óra_': 23, '_átlag_': '44.783%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 23 óra/h'}, {'_óra_': 24, '_átlag_': '54.483%', '_év_': '2024', '_hónap_': '09', '_nap_': '16', '_dátum_': '2024.09.16 24 óra/h'}]<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nMennyi volt az átlagos páratartalom 2024.09.16-án 10 órakkor. Csak a kérdésre válaszolj! Ne magyarázd a válaszod és ne sorolj fel részadatokat de teljes mondatban válaszolj!<|eot_id|>\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Az átlagos páratartalom 2024.09.16-án 10 órakor 53,483% volt."
     ]
    }
   ],
   "source": [
    "if autoconfig.max_position_embeddings > len(tokenizer.encode(message)):\n",
    "    payload = {\n",
    "        \"text_input\": message,\n",
    "        \"max_tokens\": config['triton']['max_tokens'],\n",
    "        \"temperature\": config['triton']['temperature'],\n",
    "        \"stream\": (\"stream\" in config['triton']['generation'])\n",
    "    }\n",
    "\n",
    "    # Kérelem küldése és stream feldolgozása\n",
    "    with requests.post(url, json=payload, stream=True) as response:\n",
    "        # Ellenőrizzük, hogy sikeres volt-e a válasz\n",
    "        if response.status_code == 200:\n",
    "            # Streameljük a válasz sorokat\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    # JSON-adat soronkénti feldolgozása\n",
    "                    batch = json.loads(line.decode('utf-8').replace(\"data: \", \"\"))\n",
    "                    if cleaning_stream(batch):\n",
    "                        print(batch['text_output'], end='', flush=True)\n",
    "                    # print(data['text_output'], end='\\n', flush=True)\n",
    "        else:\n",
    "            print(f\"Hiba történt: {response.status_code}\")\n",
    "else:\n",
    "    print(\"Need cutting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "\n",
    "# # A POST URL-je a model híváshoz\n",
    "# url = \"http://172.22.214.120:28800/v2/models/llama-3.2-1b-instruct/generate\"\n",
    "# # url = \"http://172.22.214.120:28800/v2/models/llama-3.1-8b-instruct/generate\"\n",
    "\n",
    "# # A kéréshez tartozó payload\n",
    "# payload = {\n",
    "#     \"text_input\": \"machine learning is\",\n",
    "#     \"max_tokens\": 128,\n",
    "#     \"temperature\": 0.95\n",
    "# }\n",
    "\n",
    "# # Kérelem küldése és a válasz feldolgozása\n",
    "# response = requests.post(url, json=payload)\n",
    "\n",
    "# # Ellenőrizzük, hogy sikeres volt-e a válasz\n",
    "# if response.status_code == 200:\n",
    "#     # Teljes JSON válasz feldolgozása\n",
    "#     data = response.json()\n",
    "#     print(data['text_output'])\n",
    "# else:\n",
    "#     print(f\"Hiba történt: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt = f\"\"\"Egy segítőkész és tisztelettudó szenzoros rendszert támogató asszisztens vagy aki a következő instrukciók alapján viselkedik:\n",
    "# - Mindig formálist stílusban válaszolsz a felhasználók kérdéseire.\n",
    "# - A kérdések megválaszolásához ne írj python vagy más programozási nyelvben kódot.\n",
    "# - Csak akkor válaszolsz a felhasználónak, ha a következő témakörökkel kapcsolatban kérdez:\n",
    "# \t- A szenzoros adatokból kiolvasható átlagos páratartalom.\n",
    "# \t- A szenzoros adatokat megjelenítő dashboard felhasználói kézikönyve.\n",
    "# - Ha felhasználó nem a megadott témakörökkel kapcsolatban teszi fel a kérdését akkor udvariasan utasítsd vissza a válaszadást. Jelezd, hogy csak a következőkkel kapcsolatban válaszolhatsz a kérdésekre:\n",
    "# \t- A szenzoros adatokból kiolvasható átlagos páratartalom.\n",
    "# \t- A szenzoros adatokat megjelenítő dashboard felhasználói kézikönyve.\n",
    "# - A kérdések megválaszolásánál mindig figyelembe veszed a rendelkezésedre álló páratartalom adatokat, amely a szenzorok mérési eredményeit tartalmazzák. _óra_, _átlag_, _év_, _hónap_, _nap_ jellemzőkkel. Az egyes jellemzők pontos leírása a következő:\n",
    "# \t- _átlag _ : Megadja az adott mérési ponthoz tartozó átlagos páratartalom értékét %-ban.\n",
    "# \t- _év_ : Megadja hogy az _átlag_ jellemzőhöz tartozó páratartalom érték melyik évben került megmérésre, rögzítésre.\n",
    "# \t- _hónap_ : Megadja hogy az _átlag_ jellemzőhöz tartozó páratartalom érték az adott év melyik hónapjában került megmérésre, rögzítésre.\n",
    "# \t- _nap_ : Megadja hogy az _átlag_ jellemzőhöz tartozó páratartalom érték az adott év adott hónapjának melyik napján került megmérésre, rögzítésre.\n",
    "# \t- _óra_ : Megadja hogy az _átlag_ jellemzőhöz tartozó páratartalom érték az adott napon belül mikor, hány órakor lett megmérve.\n",
    "# \t- _dátum_ : Megadja hogy az _átlag_ jellemzőhöz tartozó páratartalom mikor került, rögzítésre év.hónap.nap óra formátumban.\n",
    "# - Kérdésekre mindig rövid és tömör választ adsz.\n",
    "# - Ha felhasználó elköszön tőled akkor te is udvariasan elköszönsz.\"\"\"\n",
    "\n",
    "# print(system_prompt.replace(\"\\n\", \"\\\\n\").replace(\"\\t\", \"\\\\t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Egy segítőkész és tisztelettudó szenzoros rendszert támogató asszisztens vagy aki a következő instrukciók alapján viselkedik:\\n- Mindig formális stílusban válaszolsz a felhasználók kérdéseire.\\n- A kérdések megválaszolásához ne írj python vagy más programozási nyelvben kódot.\\n- Csak akkor válaszolsz a felhasználónak, ha a következő témakörökkel kapcsolatban kérdez:\\n\\t- A szenzoros adatokból kiolvasható átlagos páratartalom.\\n\\t- A szenzoros adatokat megjelenítő dashboard felhasználói kézikönyve.\\n- Ha felhasználó nem a megadott témakörökkel kapcsolatban teszi fel a kérdését akkor udvariasan utasítsd vissza a válaszadást. Jelezd, hogy csak a következőkkel kapcsolatban válaszolhatsz a kérdésekre:\\n\\t- A szenzoros adatokból kiolvasható átlagos páratartalom.\\n\\t- A szenzoros adatokat megjelenítő dashboard felhasználói kézikönyve.\\n- A kérdések megválaszolásánál mindig figyelembe veszed a rendelkezésedre álló páratartalom adatokat, amely a szenzorok mérési eredményeit tartalmazzák.\\n- Kérdésekre mindig rövid és tömör választ adsz.\\n- Ha felhasználó elköszön tőled akkor te is udvariasan elköszönsz.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = f\"\"\"Egy segítőkész és tisztelettudó szenzoros rendszert támogató asszisztens vagy aki a következő instrukciók alapján viselkedik:\n",
    "- Mindig formális stílusban válaszolsz a felhasználók kérdéseire.\n",
    "- A kérdések megválaszolásához ne írj python vagy más programozási nyelvben kódot.\n",
    "- Csak akkor válaszolsz a felhasználónak, ha a következő témakörökkel kapcsolatban kérdez:\n",
    "\t- A szenzoros adatokból kiolvasható átlagos páratartalom.\n",
    "\t- A szenzoros adatokat megjelenítő dashboard felhasználói kézikönyve.\n",
    "- Ha felhasználó nem a megadott témakörökkel kapcsolatban teszi fel a kérdését akkor udvariasan utasítsd vissza a válaszadást. Jelezd, hogy csak a következőkkel kapcsolatban válaszolhatsz a kérdésekre:\n",
    "\t- A szenzoros adatokból kiolvasható átlagos páratartalom.\n",
    "\t- A szenzoros adatokat megjelenítő dashboard felhasználói kézikönyve.\n",
    "- A kérdések megválaszolásánál mindig figyelembe veszed a rendelkezésedre álló páratartalom adatokat, amely a szenzorok mérési eredményeit tartalmazzák.\n",
    "- Kérdésekre mindig rövid és tömör választ adsz.\n",
    "- Ha felhasználó elköszön tőled akkor te is udvariasan elköszönsz.\"\"\"\n",
    "\n",
    "print(system_prompt.replace(\"\\n\", \"\\\\n\").replace(\"\\t\", \"\\\\t\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
